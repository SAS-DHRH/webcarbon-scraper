{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Website Carbon scraper\n",
    "\n",
    "This script takes a list of URL's in the urls.txt file, cleans the URL's, and scrapes the websitecarbon.com page.\n",
    "It then extracts the grams of carbon value from the HTML, and saves the results to the carbondata.csv file.\n",
    "\n",
    "I started by attempting to use MS Excel's cell formulas =WEBSERVICE() and =FILTERXML() functions, but these only work on windows. I then decided to try learning Julia, but decided it would be quicker to just use python and command line. The first version of this python notebook used wget to scrape the URL's, but in the end I needed to use requests.sessions and post the URL to the Websitecarbon.com webform to reliably retrieve the carbon data.\n",
    "\n",
    "To rerun this script, check the list of URL's in the urls.txt file are up to date, clear out any cached HTML files in the ./html directory, and run all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = open('urls.txt').readlines()\n",
    "urls = [u.rstrip('\\n').strip().rstrip('/').replace('https://', '').replace('http://', '').replace('www.', '') for u in urls]\n",
    "urls = [u for u in urls if u]  # remove empties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeWebCarbon(url):\n",
    "    '''\n",
    "    Function takes a URL and scrapes the html to the disk, then extracts the grams of carbon from the HTML header.\n",
    "    Returns a list\n",
    "    '''\n",
    "    carbonurl = 'https://www.websitecarbon.com'\n",
    "    cleanurl = url.replace('.', '-').replace('/', '-')\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    payload = {'wgd-cc-url':url,\n",
    "               'wgd-cc-retest': 'true'}\n",
    "    \n",
    "    directory = 'html'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # Make the request and save the response\n",
    "    scrapefile = \"./html/\" + cleanurl + \".html\"\n",
    "    if not os.path.exists(scrapefile) or os.path.getsize(scrapefile) == 0:\n",
    "        print('scraping ' + url)\n",
    "        session = requests.Session()\n",
    "        sess = session.post(carbonurl, headers=headers, data=payload)\n",
    "        with open(scrapefile, \"w\") as f:\n",
    "            f.write(sess.text)\n",
    "            f.close()\n",
    "    else:\n",
    "        print('using cached html for ' + url)\n",
    "        \n",
    "    # Load the cached response file and search for the data\n",
    "    grams = !grep -E 'grams\": (.*),$' ./html/{cleanurl}.html | cut -d: -f2 | cut -d, -f1\n",
    "    if len(grams) > 0:\n",
    "        grams = grams[0].strip()\n",
    "    \n",
    "    return [url, 'grams of CO2', grams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carbondata = [scrapeWebCarbon(u) for u in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('carbondata.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['url', 'type', 'value'])\n",
    "    writer.writerows(carbondata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can multiply these values by your website pageviews analytics to calculate your website's carbon footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the data\n",
    "carbondata = pd.read_csv('carbondata.csv')\n",
    "carbondata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
